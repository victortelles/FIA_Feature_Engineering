{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a928f1a8",
   "metadata": {},
   "source": [
    "# Laboratorio: Feature Engineering con el dataset Wine Quality\n",
    "\n",
    "En este notebook entrenarás un modelo de clasificación para predecir si un vino es de\n",
    "**buena calidad** o no, utilizando el dataset público *Wine Quality* de UCI.\n",
    "\n",
    "1. Primero ejecutaremos un modelo **sin Feature Engineering** (solo con las variables originales).\n",
    "2. Después, en la sección marcada como:\n",
    "\n",
    "```python\n",
    "# ============================================\n",
    "# SECCIÓN PARA FEATURE ENGINEERING (A COMPLETAR)\n",
    "# ============================================\n",
    "```\n",
    "\n",
    "deberás **crear nuevas características y/o aplicar transformaciones** (por ejemplo,\n",
    "transformaciones logarítmicas, relaciones entre variables, escalado, etc.) y volver\n",
    "a entrenar el modelo para analizar la mejora en el desempeño.\n",
    "\n",
    "Alumno: Victor Manuel Telles Amezcua | 737066"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c532c382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 1. IMPORTACIÓN DE LIBRERÍAS\n",
    "# ============================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c3cd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================\n",
    "# 2. CARGA DE DATOS\n",
    "# ==================\n",
    "\n",
    "# IMPORTANTE:\n",
    "# Descarga el archivo winequality-red.csv o winequality-white.csv desde UCI\n",
    "# y colócalo en la misma carpeta que este notebook.\n",
    "# En UCI el separador es ';', por eso usamos sep=';'.\n",
    "\n",
    "csv_path = \"data/winequality-red.csv\"  # <- Cambia a winequality-white.csv si lo prefieres\n",
    "\n",
    "data = pd.read_csv(csv_path, sep=';')\n",
    "\n",
    "print(\"Primeras filas del dataset:\")\n",
    "display(data.head())\n",
    "\n",
    "print(\"\\nInformación general del dataset:\")\n",
    "print(data.info())\n",
    "\n",
    "print(\"\\nEstadísticas descriptivas:\")\n",
    "display(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9752dc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 3. CREACIÓN DE LA VARIABLE OBJETIVO BINARIA (LABEL)\n",
    "# ======================================================\n",
    "\n",
    "# La columna 'quality' toma valores enteros (por ejemplo, de 3 a 8).\n",
    "# Definimos \"buen vino\" si quality >= 6, y \"no tan bueno\" si quality <= 5.\n",
    "\n",
    "data['good_quality'] = (data['quality'] >= 6).astype(int)\n",
    "\n",
    "# Variable objetivo\n",
    "y = data['good_quality']\n",
    "\n",
    "# Variables de entrada: todas las columnas excepto 'quality' y 'good_quality'\n",
    "X = data.drop(columns=['quality', 'good_quality'])\n",
    "\n",
    "print(\"Columnas de entrada (features):\")\n",
    "print(X.columns)\n",
    "\n",
    "print(\"\\nDistribución de la variable objetivo (0 = calidad baja, 1 = calidad alta):\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fe9cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# 4. DIVISIÓN EN CONJUNTOS DE ENTRENAMIENTO\n",
    "#    Y PRUEBA (SIN FEATURE ENGINEERING)\n",
    "# ===========================================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Tamaño del conjunto de entrenamiento:\", X_train.shape)\n",
    "print(\"Tamaño del conjunto de prueba:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20531b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================\n",
    "# 5. MODELO BASE k-NN SIN TRANSFORMACIÓN\n",
    "# =======================================\n",
    "\n",
    "# Usamos k-NN con k=5 como modelo sencillo de referencia.\n",
    "# NOTA: aquí no aplicamos ningún tipo de feature engineering\n",
    "# (no hay escalado, ni nuevas columnas, ni transformaciones).\n",
    "# Esto es intencional: servirá como línea base para comparar\n",
    "# después de aplicar feature engineering.\n",
    "\n",
    "knn_base = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Entrenamiento del modelo con los datos originales\n",
    "knn_base.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones en el conjunto de prueba\n",
    "y_pred_base = knn_base.predict(X_test)\n",
    "\n",
    "# Cálculo de métricas\n",
    "accuracy_base = accuracy_score(y_test, y_pred_base)\n",
    "\n",
    "print(f\"Accuracy del modelo BASE (sin Feature Engineering): {accuracy_base:.4f}\\n\")\n",
    "print(\"Reporte de clasificación (modelo base):\")\n",
    "print(classification_report(y_test, y_pred_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b1aba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# 6. MATRIZ DE CONFUSIÓN (MODELO BASE)\n",
    "# ====================================\n",
    "\n",
    "cm_base = confusion_matrix(y_test, y_pred_base)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_base)\n",
    "\n",
    "ax.set_title(\"Matriz de confusión - Modelo base (sin FE)\")\n",
    "ax.set_xlabel(\"Predicción\")\n",
    "ax.set_ylabel(\"Real\")\n",
    "\n",
    "# Etiquetas de los ejes\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_yticks([0, 1])\n",
    "ax.set_xticklabels(['0', '1'])\n",
    "ax.set_yticklabels(['0', '1'])\n",
    "\n",
    "# Mostrar los números en cada celda\n",
    "for i in range(cm_base.shape[0]):\n",
    "    for j in range(cm_base.shape[1]):\n",
    "        ax.text(j, i, cm_base[i, j],\n",
    "                ha='center', va='center', color='black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba384d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 7. SECCIÓN PARA FEATURE ENGINEERING (A COMPLETAR POR EL/LA ESTUDIANTE)\n",
    "# =============================================================================\n",
    "# En esta sección deberás:\n",
    "#   - Crear nuevas características a partir de X_train y X_test.\n",
    "#     Ejemplos:\n",
    "#        * Transformaciones logarítmicas sobre variables muy sesgadas.\n",
    "#        * Relaciones entre variables (ratios, productos, diferencias, etc.).\n",
    "#   - Opcional pero MUY recomendado: aplicar escalado (por ejemplo MinMaxScaler\n",
    "#     o StandardScaler), recordando:\n",
    "#        * Ajustar el escalador SOLO con X_train.\n",
    "#        * Aplicar la transformación al conjunto de prueba X_test.\n",
    "#\n",
    "# IMPORTANTE:\n",
    "#   - NO modifiques X_train y X_test originales.\n",
    "#   - Trabaja sobre copias: X_train_fe y X_test_fe.\n",
    "#   - Al final de tus transformaciones, las variables que usará el modelo deben\n",
    "#     llamarse:\n",
    "#          X_train_model\n",
    "#          X_test_model\n",
    "#\n",
    "#   De momento, dejamos esta sección de manera que, si no cambias nada,\n",
    "#   el modelo usará exactamente las mismas características originales.\n",
    "# =============================================================================\n",
    "\n",
    "# 7.1 Copiamos los conjuntos originales (NO MODIFICAR ESTAS LÍNEAS)\n",
    "X_train_fe = X_train.copy()\n",
    "X_test_fe = X_test.copy()\n",
    "\n",
    "# 7.2 >>>>> AQUÍ AGREGA TU CÓDIGO DE FEATURE ENGINEERING <<<<<\n",
    "# Ejemplo de ideas (NO se ejecutan hasta que les quites el comentario):\n",
    "#\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "#\n",
    "# # a) Crear nuevas columnas (ejemplos hipotéticos):\n",
    "# X_train_fe['sulfur_ratio'] = X_train_fe['free sulfur dioxide'] / X_train_fe['total sulfur dioxide']\n",
    "# X_test_fe['sulfur_ratio'] = X_test_fe['free sulfur dioxide'] / X_test_fe['total sulfur dioxide']\n",
    "#\n",
    "# # b) Transformación logarítmica (evitar log(0) sumando 1):\n",
    "# X_train_fe['log_residual_sugar'] = np.log1p(X_train_fe['residual sugar'])\n",
    "# X_test_fe['log_residual_sugar'] = np.log1p(X_test_fe['residual sugar'])\n",
    "#\n",
    "# # c) Escalado Min-Max:\n",
    "# scaler = MinMaxScaler()\n",
    "# X_train_fe = pd.DataFrame(\n",
    "#     scaler.fit_transform(X_train_fe),\n",
    "#     columns=X_train_fe.columns,\n",
    "#     index=X_train_fe.index\n",
    "# )\n",
    "# X_test_fe = pd.DataFrame(\n",
    "#     scaler.transform(X_test_fe),\n",
    "#     columns=X_test_fe.columns,\n",
    "#     index=X_test_fe.index\n",
    "# )\n",
    "#\n",
    "# IMPORTANTE: si usas MinMaxScaler u otro escalado, NO olvides importar\n",
    "# la clase correspondiente en la celda de librerías.\n",
    "\n",
    "# 7.3 AL FINAL de tus transformaciones, asegúrate de que estas variables\n",
    "#     apunten a las versiones definitivas que quieres usar en el modelo:\n",
    "\n",
    "X_train_model = X_train_fe   # <- Reemplaza si usas versión escalada, etc.\n",
    "X_test_model = X_test_fe     # <- Reemplaza si usas versión escalada, etc.\n",
    "\n",
    "print(\"Dimensiones de X_train_model y X_test_model después de Feature Engineering:\")\n",
    "print(X_train_model.shape, X_test_model.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a75c2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 8. MODELO k-NN DESPUÉS DE FEATURE ENGINEERING\n",
    "# =====================================================\n",
    "\n",
    "# Importante: aquí se usa X_train_model y X_test_model,\n",
    "# que pueden contener nuevas características y/o datos escalados.\n",
    "\n",
    "knn_fe = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "knn_fe.fit(X_train_model, y_train)\n",
    "y_pred_fe = knn_fe.predict(X_test_model)\n",
    "\n",
    "accuracy_fe = accuracy_score(y_test, y_pred_fe)\n",
    "\n",
    "print(f\"Accuracy del modelo con Feature Engineering: {accuracy_fe:.4f}\\n\")\n",
    "print(\"Reporte de clasificación (con Feature Engineering):\")\n",
    "print(classification_report(y_test, y_pred_fe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc496ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# 9. COMPARACIÓN Y PREGUNTAS DE REFLEXIÓN\n",
    "# =========================================\n",
    "\n",
    "print(f\"Accuracy modelo BASE (sin FE):   {accuracy_base:.4f}\")\n",
    "print(f\"Accuracy modelo con FE:          {accuracy_fe:.4f}\")\n",
    "\n",
    "mejora = accuracy_fe - accuracy_base\n",
    "print(f\"\\nMejora absoluta en accuracy: {mejora:.4f}\")\n",
    "\n",
    "print(\"\"\"\n",
    "Reflexiona y responde (puedes hacerlo en una celda de Markdown aparte):\n",
    "\n",
    "1. ¿Qué transformaciones de Feature Engineering aplicaste?\n",
    "2. ¿Qué variables nuevas creaste y por qué?\n",
    "3. ¿Cómo cambiaron las métricas (accuracy, precision, recall, F1)?\n",
    "4. ¿Por qué crees que esas transformaciones ayudaron (o no ayudaron) al modelo?\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
